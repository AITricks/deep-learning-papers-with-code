这张图描绘了整个AST模型的**宏观流水线（整体架构）** 和**核心模块的微观结构（ASSA与FRFN）**。我们可以将其分为三大部分来理解。

---

![结构图](https://gitee.com/ChadHui/typora-image/raw/master/cv-image/20251022214424.jpg)

### 第一部分：整体架构 —— 一个高效的U形流水线

整个模型是一个**编码器-解码器（Encoder-Decoder）** 结构，就像一座现代化的**信息精炼工厂**。

**1. 输入与初步处理（原材料入库）：**
- **输入**：一张退化图像（Degraded Image `I`），例如有雨、有雾的图像。
- **第一步**：经过一个**卷积层（Conv）**，将原始的3通道（RGB）图像转换为一个更深层的特征图 `F_0`。这相当于对原材料进行初步的分类和贴上初始标签。

**2. 编码器（Encoder - 信息压缩与提炼）：**
- **目标**：逐步提取图像的深层特征，并缩小特征图尺寸（下采样），以扩大感受野。
- **过程**：`F_0` 依次通过 `N_1` 个**编码阶段（Stage）**。
- **每个阶段的结构**：
    - 包含 `N_2` 个**基础块**。**注意：论文中指出，编码器中的基础块只包含 `FRFN` 模块，而没有 `ASSA`**。这是因为在浅层，局部细节信息比全局依赖更重要。
    - 每个阶段最后有一个**卷积下采样层（Conv）**，用于降低分辨率、增加通道数。

**3. 瓶颈层（Bottleneck - 核心信息交互中心）：**
- 这是连接编码器和解码器的部分，特征图尺寸最小，但通道数最多，语义信息最丰富。
- 在这里，模型使用包含 **`ASSA`** 和 **`FRFN`** 的完整Transformer块，来**建模最长的依赖关系**，进行全局信息的深度整合与过滤。

**4. 解码器（Decoder - 信息重建与恢复）：**
- **目标**：逐步将提炼后的深层特征上采样，恢复出清晰的图像。
- **过程**：与编码器对称，依次通过 `N_1` 个**解码阶段**。
- **每个阶段的结构**：
    - 首先有一个**卷积上采样层（Conv）**，用于提高分辨率、减少通道数。
    - 然后包含 `N_2` 个**基础块**。**注意：解码器中的每个基础块都包含了完整的 `ASSA` 和 `FRFN` 模块**。因为在重建清晰图像时，既需要全局信息来保证结构合理，也需要精细的局部特征来恢复细节。
- **跳跃连接**：解码器每一阶段的特征都会与编码器对应阶段的特征通过**恒等连接**融合。这确保了在重建过程中不会丢失早期提取的宝贵细节。

**5. 输出（成品出厂）：**
- 解码器输出的深层特征 `F_d` 经过一个最终的**卷积层（Conv）**，生成**残差图像 `R`**。
- 最终，将残差图像与原始退化图像相加，得到**复原后的清晰图像**：`Î = I + R`。模型学习的是“差了什么”，然后把它补回去。

---

### 第二部分：核心模块详解① —— 自适应稀疏自注意力（ASSA）

ASSA是整个模型的**智能信息过滤器**，它的结构图展示了其精妙的双分支设计。

**1. 输入与投影：**
- 输入特征经过**层归一化（LN）** 后，被线性投影为**查询（Q）**、**键（K）**、**值（V）** 三个矩阵。

**2. 双分支并行计算：**
这是ASSA的**灵魂所在**，两条生产线同时开工：
- **稀疏分支（Sparse Branch/SSA）**：
    - 计算 `Q` 和 `K` 的相似度矩阵 `QK^T`，并除以缩放因子 `√d`，加上相对位置偏置 `B`。
    - **关键步骤**：不使用Softmax，而是使用 **`ReLU²`** 函数。这个函数会将相似度矩阵中的所有**负值直接置为零**，实现了**硬稀疏**。它像一个**严格的质检员**，只允许“正相关”的强交互通过，彻底过滤掉微弱和负面的噪声交互。
    - 输出是稀疏的注意力权重 `SSA`。

- **稠密分支（Dense Branch/DSA）**：
    - 使用传统的 **`Softmax`** 函数处理相同的 `QK^T/√d + B`。
    - Softmax会将所有值转换为正数且和为1，它**保留所有交互信息**，无论强弱。它像一个**宽容的收集员**，确保没有任何潜在的有用信息被遗漏，但可能混入一些噪声。

**3. 自适应融合：**
- 两个分支的注意力权重 `SSA` 和 `DSA` 不会直接与 `V` 相乘。
- 它们分别与两个**可学习的权重 `w1` 和 `w2`** 相乘，然后相加。
- `w1` 和 `w2` 是通过Softmax归一化的，初始值相等。在训练中，模型会**自己学会**在当前层、当前任务下，更应该相信严格的稀疏分支还是宽容的稠密分支。
- 最终，融合后的注意力权重 `(w1*SSA + w2*DSA)` 与 `V` 相乘，得到ASSA模块的输出。

**总结**：ASSA没有在“稀疏”和“稠密”之间二选一，而是提供了一个**可自适应调节的开关**，让模型自己决定信息的“过滤强度”，兼具了二者的优点。

---

### 第三部分：核心模块详解② —— 特征精炼前馈网络（FRFN）

如果说ASSA是在**空间维度**（Token与Token之间）上做过滤，那么FRFN就是在**通道维度**（每个Token内部的特征通道之间）上做精炼。它遵循 **“增强-缓解”** 的流水线。

**1. 增强阶段：**
- 输入特征经过一个**部分卷积（PConv）**。PConv只对输入通道的一部分进行卷积运算，这本身就是一种**通道选择**机制，它强制网络**优先增强和利用最重要的那部分特征**。
- 然后通过一个线性层 `W1` 和 **GELU** 激活函数。

**2. 缓解阶段：**
- 将上一步得到的特征在**通道维度上切分为两半**：`X‘_1` 和 `X’_2`。
- **`X‘_2`** 这一半经过**重塑（Reshape）**、**深度卷积（DWConv）**、**展平（Flatten）** 操作，再通过一个Sigmoid函数，生成一个**0到1之间的门控信号**。这个信号标识了哪些特征是冗余的（值接近0）或重要的（值接近1）。
- **`X‘_1`** 这一半与上述门控信号进行**逐元素乘法**。这就实现了**“缓解”**：重要的特征被保留，冗余的特征被抑制。

**3. 最终投影：**
- 缓解后的特征再通过一个线性层 `W2` 和 **GELU** 激活函数，形成FRFN的最终输出。

**总结**：FRFN通过“部分卷积增强”和“门控缓解”两步操作，有效地提升了特征的信噪比，与ASSA在空间上的去噪形成了完美的互补。

---

### 最终总结

这张结构图清晰地展示了一个高效、精准的图像复原模型：
- **宏观上**，它采用经典的U-Net架构保证信息流动。
- **微观上**，它用**ASSA（智能空间过滤器）** 和 **FRFN（智能通道精炼器）** 这两个核心模块，从**两个维度（空间和通道）系统性地解决了Transformer在图像复原中的两大顽疾：噪声交互和特征冗余**。

整个模型就像一个精密的处理器：**编码器（FRFN）** 进行初步提纯，**瓶颈层（ASSA+FRFN）** 进行深度精炼和去芜存菁，**解码器（ASSA+FRFN）** 则利用净化后的信息高质量地重建出清晰图像。