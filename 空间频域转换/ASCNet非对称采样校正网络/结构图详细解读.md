# ASCNet 核心架构图 (Fig 1-4) 解读

---

### 1. 动机图解 (Figure 1 & 2)：问题的提出

Figure 1 和 Figure 2 是理解本文核心动机的关键。它们共同阐释了为什么传统的对称小波 U-Net (DWT/IDWT) 架构在去条纹任务上会失败。

* **Figure 1(c) & 1(d)：问题的根源——“交叉污染” (Crosstalk)**
    * Figure 1(c) 展示了当一个**特征图 S**（而非原始图像 P）被送入 DWT 时会发生什么。DWT 确实将条纹噪声（主要存在于 S 中）聚合到了低频子带 ($S_{ll}$) 和水平子带 ($S_{hl}$) 中。
    * 然而，在 U-Net 的编码器中，这些子带会被拼接 (Concatenate) 并送入一系列标准的 CNN 卷积层 ( $f_s(\cdot)$ ) 进行深度特征提取，得到 $K_c$。
    * **关键问题**在于：CNN 的卷积核具有“信道间信息交互” (channel-wise information interaction) 的特性。如 Figure 1(d) 的可视化所示，这种交互导致了**“交叉污染”**：原本干净的垂直子带 ($K_{lh}$) 和对角子带 ($K_{hh}$) 被 $S_{ll}$ 和 $S_{hl}$ 中的条纹噪声“重新污染”了。

* **Figure 2(a)：问题的显现——“跨层级列语义鸿沟”**
    * Figure 2(a) 展示了对称采样 (Symmetric Sampling: DWT/IDWT) 的解码过程。解码器使用逆小波变换 (IDWT) 作为上采样器。
    * IDWT 的工作依赖一个**固定的先验假设**：它假设输入的 $K_c$ 中，各个子带 ($K_{ll}, K_{lh}, K_{hl}, K_{hh}$) 完美对应着低频、垂直、水平、对角信息。
    * 但正如 Figure 1(d) 所示，这个假设已经不成立了（$K_{lh}$ 和 $K_{hh}$ 已被污染）。强行使用 IDWT 这个“错误的解码器”来重建特征，会导致严重的“**跨层级列语义鸿沟**” (cross-level column semantic gap)。
    * 如图 2(a) 中的 CMRC (列均值响应曲线) 所示，在 IDWT 上采样（红线变为黑线）后，特征的列响应出现了剧烈且错误的波动（红色框高亮处），导致重建图像偏离了真实的列分布。

* **Figure 2(b)：解决方案——非对称采样 (Asymmetric Sampling)**
    * Figure 2(b) 展示了本文提出的非对称采样 (DWT/PS)。它用 **Pixel Shuffle (PS) 像素重组** 替换了 IDWT。
    * **核心优势**：PS 是一种“**无语义偏差**” (semantic-bias-free) 的上采样器。它不依赖任何固定的先验假设，也不进行复杂的线性计算。它只是简单地将低分辨率特征图的像素“重新排列” (reorganizes) 到高分辨率空间中。
    * **效果对比**：如图 2(b) 的 CMRC 所示，PS 的上采样过程（红线变为黑线）非常平滑，其列语义波动更加稳定。这证明了 PS 在解码被污染的条纹特征时，具有“**更优越的语义衔接能力**” (superior semantic articulation)，从而避免了语义鸿沟。

### 2. 整体网络架构 (Figure 3)：ASCNet 的数据流

Figure 3 是 ASCNet 的总架构图，它清晰地展示了数据如何在一个“非对称 U-Net” 中流动的。

![结构图](https://gitee.com/ChadHui/typora-image/raw/master/cv-image/20251029104821.jpg)

1.  **输入与浅层特征**：
    * 输入是“Degraded image ($I_D$)”。
    * 首先经过两个卷积层，提取浅层特征 $F_0$ 和 $F_1$。

2.  **编码器路径 (Encoder Path) (红色粗箭头)**：
    * 这是一个包含 3 个阶段的下采样路径。
    * 在每个阶段，特征图首先通过一个 **RHDWT (Residual Haar Discrete Wavelet Transform)** 模块 进行下采样（分辨率 H/2, W/2）。
    * 紧接着，下采样后的特征被送入一个 **CNCM (Column Non-uniformity Correction Module)** 模块 进行深度的特征增强和校正。

3.  **解码器路径 (Decoder Path) (蓝色粗箭头)**：
    * 这是一个包含 3 个阶段的上采样路径。
    * 在每个阶段，特征图通过 **Pixel Shuffle (PS)** 模块 进行上采样（分辨率 2H, 2W），这构成了“非对称”的核心。

4.  **跳跃连接 (Skip Connection) (黑色箭头)**：
    * ASCNet 采用了长跳跃连接 来融合编码器（下采样路径）和解码器（上采样路径）的特征。
    * **融合机制**：
        1.  编码器特征（来自 CNCM）和解码器特征（来自 PS）被**拼接 (Concatenate)**。
        2.  使用 $3 \times 3$ 卷积来统一信道维度。
        3.  使用 $1 \times 1$ 卷积将信道数减半。
        4.  融合后的特征**再次**被送入一个 **CNCM** 模块，以在融合了多尺度信息后，精细地分离条纹和纹理细节。

5.  **输出 (Output)**：
    * 经过最后两个卷积层（增强高分辨率特征 $F_d$） 和一个 $1 \times 1$ 卷积 + Tanh 激活函数，网络输出的是残差条纹噪声 $I_N$。
    * 最终，输出的噪声 $I_N$ 与原始输入 $I_D$ 相加 (Element-wise Addition)，得到最终的去条纹“Output ($I_O$)”。

### 3. 核心创新模块详解 (Figure 3 & 4)

#### 3.1 RHDWT (Figure 3(b))：融合先验与语义的下采样器

RHDWT 是 ASCNet 的定制化下采样器，其结构如图 3(b) 所示，旨在解决传统 DWT 缺乏语义交互、而传统步进卷积又缺乏方向先验的问题。

![结构图](https://gitee.com/ChadHui/typora-image/raw/master/cv-image/20251029104821.jpg)

* **结构**：它是一个双分支并行结构。
* **分支 1：模型驱动分支 (Model-driven Branch)**
    * **数据流**：输入特征 $I_i$ 首先通过 **HDWT** (Haar 小波) 分解为 4 个子带。这 4 个子带被拼接（在信道维度），然后通过一个 $3 \times 3$ 卷积 ($f_{3\times3}^{\delta}$) 进行语义融合。
    * **目的**：利用 HDWT 的固定滤波器来**融合条纹的方向先验知识** (stripe-directional prior knowledge)。
* **分支 2：残差分支 (Residual Branch)**
    * **数据流**：输入特征 $I_i$ 直接通过一个**步长为 2 的 $3 \times 3$ 卷积** ($f_{3\times3}^{s=2}$)。
    * **目的**：这是一个标准的数据驱动 (data-driven) 路径，用于捕获和补充模型驱动分支所缺乏的**跨信道语义和空间特征**。
* **融合**：
    * 两个分支的输出特征 $I_{model}^{out}$ 和 $I_{res}^{out}$ 被**逐元素相加** (Element-wise Addition) 得到最终的输出 $I_R$。
    * **总结 (Eq. 9)**：$I_R = I_{model}^{out} + I_{res}^{out}$。这种并行设计使得网络在下采样时，既能利用小波的物理先验来分解条纹，又能利用 CNN 的强大能力来学习语义表征。

#### 3.2 CNCM / RCSSC (Figure 3(c) & Figure 4)：全局列特征校正

CNCM 是网络的核心特征增强模块。

* **DCR 结构 (Figure 3(c))**：
    * 首先，Figure 3(c) 展示了 CNCM 的宏观结构：它将多个 **RCSSC** 块（即将详述）嵌入到一个**密集连接残差 (DCR)** 结构中。
    * 如图所示，特征流被密集地连接（通过拼接 C 和残差 +），这有助于增强信息流和特征重用 (feature reusing)。

* **RCSSC 块 (Figure 4)**：
    * Figure 4 是 CNCM 的核心单元 RCSSC (Residual Column Spatial Self-Correction)。它由一个残差连接包裹着 CSSC 块。CSSC 块包含三个并行的注意力分支：

    1.  **SAB (Figure 4(b))：空间注意力分支**
        * **结构**：这是一个标准空间注意力。它对输入 $X$ 沿**信道** (Channel) 维度进行全局平均池化 (GAP) 和全局最大池化 (GMP)。两者拼接后，通过一个 $3 \times 3$ 卷积和 Sigmoid 激活，生成一个空间权重图 SA。
        * **目的**：利用空间相关性，增强关键区域的结构特征。

    2.  **CAB (Figure 4(c))：列注意力分支**
        * **结构**：这是最关键的分支之一。
            a. 它首先对输入 $X$ 沿**空间高度** (Height) 维度（即按列）进行列平均池化 (CAP) 和列最大池化 (CMP)（池化核大小为 Hx1）。
            b. 两个 $C \times 1 \times W$ 的列特征被拼接 (C) 得到 $M_c$。
            c. $M_c$ 经过 1x1 卷积 (CBL) 后，被**拆分 (Split)** 为 $X_a$ 和 $X_m$ 两个分支。
            d. 这两个分支再各自通过一个信道注意力模块（EXC，即 Conv+BN+ReLU+Conv+Sigmoid） 生成列权重。
            e. 最终输出 CA 是输入 $X$ 与这两个权重相乘的结果。
        * **目的**：条纹噪声是按列分布的。此分支通过显式地建模“列依赖性” (column dependencies)，强化列特征，以克服条纹的列间差异。

    3.  **SCB (Figure 4(d))：自校准分支**
        * **结构**：此分支用于建立长程依赖。
            a. 输入 $X$ 首先通过**平均池化**（如 $2 \times 2$， $\mathcal{H}_2$）进行下采样。
            b. 然后通过卷积 (Conv)。
            c. 再通过**上采样**（如双线性插值， $\mathcal{B}_2$）恢复原始分辨率。
            d. 结果与原始输入 $X$ 相加（残差连接），最后通过 Sigmoid 激活 生成最终的自校准权重 SC。
        * **目的**：聚合全局上下文信息，建立灵活的“远程依赖” (remote dependencies)，以微调全局均匀性。

* **RCSSC 最终融合 (Eq. 10)**：
    * 如图 4 底部所示，SAB 和 CAB 的输出被拼接 并通过 $1 \times 1$ 卷积融合。
    * 融合后的结果与 SCB 的输出 (SC) 进行广播 Hadamard 乘积 ( $\odot$ )。
    * 最后，通过残差连接 加上原始输入 $X$。

### 4. 图解总结

ASCNet 的架构图设计巧妙地解决了 Figure 1 和 2 中提出的“跨层级列语义鸿沟”问题：

1.  **问题**：DWT/IDWT 对称采样中的 IDWT 上采样器，其固定的先验假设与 CNN 造成的特征“交叉污染” (Fig 1c, 1d) 相冲突，导致了“语义鸿沟” (Fig 2a)。
2.  **解决方案 (ASCNet 架构, Fig 3)**：
    * **编码器 (RHDWT, Fig 3b)**：使用 RHDWT 双分支结构，在下采样时就融合了“条纹方向先验”（模型驱动分支）和“跨信道语义”（残差分支），获得了更鲁棒、信息更丰富的编码特征。
    * **解码器 (PS, Fig 3a)**：抛弃 IDWT，采用“无语义偏差”的 Pixel Shuffle 作为上采样器。如图 2(b) 所示，PS 具有更强的语义衔接能力，能平滑地解码被污染的特征，从根本上避免了“语义鸿沟”的产生。
    * **校正器 (CNCM/RCSSC, Fig 4)**：在网络的编码、解码和跳跃连接的每个关键节点都插入了强大的 CNCM 模块。该模块利用其三大分支（列注意 CAB、空间注意 SAB、自校准 SCB） 来捕获全局上下文和长程列依赖，从而能精确地区分条纹噪声和真实的场景垂直结构。
